{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Python 2 & 3 Compatibility\n",
    "from __future__ import print_function, division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Probability Intro\n",
    "\n",
    "A *random variable* is an entity that takes on one of a range of possible values, each with a certain probability.  So, for example, each toss of a coin or roll of a die is a distinct realization of a random variable.  Often, we think of our \"rows\" of data as realizations of a (very complicated) random variable.\n",
    "\n",
    "Imagine a sequence where a coin is flipped that has probability .6 of being heads and two dice are rolled.  One of the dice is a standard 6-sided die, but the other is a loaded die where the probabilities of the six sided are unbalanced.  Specifically, on the loaded die, the probability of a 1 is 1/2 while the probabilities of the other 5 sides are each 0.1.  An observer sees the result of one of the dice, depending on the coin toss.  If the coin is heads the observer sees the fair die, but if it is tails, she sees the loaded die.  However, the observer does not know which die she is seeing, she just sees the result.\n",
    "\n",
    "In this scenario, what are the different random variables that we could define?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we will simulate many repeated trials of these random variables to try to develop some intuition around probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set the number of trials\n",
    "num_obs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Simulate a coin toss (or more accurately num_obs of them)\n",
    "# We will use the convention that \"heads\" is 1 and \"tails\" is 0\n",
    "np.random.seed(42)\n",
    "\n",
    "coin_toss = np.random.binomial(1,.6, num_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0,\n",
       "       1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0,\n",
       "       0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "       0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0,\n",
       "       1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1,\n",
       "       0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0,\n",
       "       1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "       0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
       "       0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0,\n",
       "       1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0,\n",
       "       1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0,\n",
       "       0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n",
       "       0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1,\n",
       "       1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
       "       0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1,\n",
       "       0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coin_toss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    613\n",
       "0    387\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Type some code here to convince yourself that the data looks right\n",
    "# E.g. plot, look at the raw data, look at summary statistics of the data\n",
    "\n",
    "pd.Series(coin_toss).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 387.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,  613.]),\n",
       " array([ 0. ,  0.1,  0.2,  0.3,  0.4,  0.5,  0.6,  0.7,  0.8,  0.9,  1. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEACAYAAACwB81wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10eea35f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(coin_toss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Simulate a fair six-sided die roll\n",
    "fair_die_roll = np.random.randint(1,7, num_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 6, 3, 5, 1, 5, 6, 6, 1, 2, 1, 4, 3, 2, 1, 5, 2, 2, 1, 2, 5, 6, 2,\n",
       "       6, 5, 1, 3, 2, 3, 5, 2, 6, 4, 3, 2, 3, 2, 1, 6, 3, 4, 4, 5, 2, 3, 5,\n",
       "       3, 2, 4, 1, 4, 5, 6, 1, 5, 2, 1, 5, 2, 4, 6, 2, 3, 2, 2, 6, 3, 5, 5,\n",
       "       2, 3, 3, 6, 4, 5, 6, 1, 5, 6, 5, 4, 1, 4, 1, 2, 6, 1, 4, 5, 1, 6, 1,\n",
       "       3, 5, 6, 6, 2, 4, 2, 6, 5, 1, 1, 5, 6, 1, 1, 1, 4, 4, 3, 2, 5, 5, 5,\n",
       "       3, 4, 6, 6, 3, 6, 5, 2, 1, 4, 4, 3, 4, 5, 6, 5, 3, 5, 6, 2, 3, 2, 1,\n",
       "       2, 1, 1, 2, 3, 6, 5, 5, 6, 1, 1, 3, 4, 2, 1, 5, 3, 2, 3, 2, 2, 6, 1,\n",
       "       3, 3, 6, 5, 5, 1, 1, 4, 6, 5, 2, 3, 1, 3, 3, 4, 5, 1, 3, 1, 2, 4, 2,\n",
       "       1, 1, 5, 3, 3, 2, 4, 6, 3, 5, 2, 2, 6, 5, 4, 5, 4, 5, 5, 1, 2, 5, 6,\n",
       "       5, 3, 2, 3, 2, 3, 5, 5, 1, 6, 3, 4, 1, 3, 3, 1, 5, 3, 5, 1, 5, 2, 4,\n",
       "       3, 6, 4, 5, 3, 5, 2, 1, 3, 2, 2, 3, 5, 6, 2, 4, 2, 6, 5, 5, 4, 2, 5,\n",
       "       6, 3, 1, 1, 1, 2, 4, 5, 3, 6, 3, 6, 2, 1, 2, 4, 4, 6, 5, 5, 6, 4, 4,\n",
       "       4, 2, 4, 3, 1, 4, 6, 1, 2, 6, 1, 6, 2, 3, 2, 2, 6, 5, 4, 4, 3, 3, 4,\n",
       "       5, 4, 5, 3, 1, 6, 3, 3, 2, 2, 2, 6, 2, 5, 4, 1, 3, 5, 1, 5, 5, 3, 4,\n",
       "       2, 6, 4, 6, 3, 3, 3, 1, 6, 4, 4, 5, 5, 5, 3, 4, 6, 3, 1, 5, 3, 3, 1,\n",
       "       2, 4, 6, 2, 5, 3, 1, 1, 4, 2, 4, 3, 4, 6, 1, 1, 5, 5, 3, 6, 2, 4, 3,\n",
       "       5, 4, 5, 4, 2, 3, 4, 6, 1, 6, 6, 1, 6, 4, 4, 4, 1, 6, 1, 4, 6, 6, 5,\n",
       "       5, 2, 3, 5, 1, 5, 2, 6, 2, 6, 6, 3, 5, 1, 1, 4, 6, 1, 3, 6, 3, 1, 1,\n",
       "       4, 1, 6, 6, 6, 4, 4, 1, 2, 2, 4, 1, 2, 1, 1, 1, 5, 6, 1, 5, 4, 2, 6,\n",
       "       2, 6, 2, 6, 2, 2, 2, 2, 4, 1, 3, 5, 3, 3, 6, 1, 6, 1, 1, 2, 4, 2, 4,\n",
       "       6, 4, 6, 3, 3, 4, 4, 6, 2, 6, 2, 3, 1, 4, 2, 6, 3, 2, 6, 4, 4, 5, 1,\n",
       "       5, 3, 2, 3, 6, 4, 5, 5, 5, 3, 4, 2, 6, 2, 3, 6, 5, 1, 3, 3, 4, 2, 3,\n",
       "       3, 5, 5, 6, 1, 4, 1, 6, 5, 2, 5, 4, 5, 4, 4, 4, 6, 4, 4, 2, 1, 3, 1,\n",
       "       4, 2, 5, 2, 4, 2, 2, 4, 6, 2, 3, 3, 2, 6, 5, 4, 3, 5, 2, 5, 1, 3, 2,\n",
       "       4, 6, 2, 4, 6, 6, 2, 5, 5, 6, 5, 1, 6, 6, 4, 5, 6, 1, 4, 2, 6, 1, 3,\n",
       "       1, 1, 4, 2, 3, 5, 5, 1, 4, 4, 5, 3, 2, 3, 6, 6, 2, 5, 2, 4, 6, 1, 1,\n",
       "       5, 4, 3, 4, 1, 1, 6, 4, 4, 1, 3, 5, 5, 4, 5, 1, 1, 4, 4, 6, 4, 3, 5,\n",
       "       4, 2, 6, 2, 1, 5, 4, 2, 5, 1, 3, 6, 5, 5, 3, 5, 1, 1, 3, 6, 4, 2, 4,\n",
       "       5, 2, 3, 3, 6, 2, 1, 2, 5, 1, 3, 2, 4, 6, 4, 6, 5, 4, 2, 2, 4, 2, 5,\n",
       "       1, 5, 6, 5, 6, 2, 1, 2, 3, 2, 6, 2, 2, 1, 2, 1, 4, 3, 1, 6, 4, 1, 1,\n",
       "       3, 6, 5, 5, 1, 2, 6, 4, 2, 2, 6, 1, 1, 1, 1, 5, 1, 5, 5, 1, 3, 4, 2,\n",
       "       5, 6, 6, 4, 6, 3, 6, 2, 2, 5, 1, 3, 5, 3, 1, 6, 6, 1, 5, 1, 4, 2, 5,\n",
       "       3, 4, 5, 1, 1, 1, 1, 3, 4, 6, 2, 3, 3, 6, 6, 2, 2, 6, 1, 3, 5, 2, 2,\n",
       "       6, 4, 5, 5, 2, 1, 4, 5, 2, 5, 4, 4, 3, 6, 6, 2, 4, 3, 3, 5, 5, 3, 5,\n",
       "       4, 1, 4, 3, 3, 4, 5, 5, 6, 3, 2, 6, 5, 4, 5, 4, 6, 3, 5, 4, 3, 2, 4,\n",
       "       6, 2, 2, 1, 5, 4, 2, 1, 6, 3, 4, 2, 5, 1, 2, 5, 2, 4, 4, 4, 6, 6, 1,\n",
       "       4, 5, 2, 3, 5, 6, 6, 5, 6, 4, 1, 2, 1, 2, 2, 1, 5, 2, 1, 2, 3, 5, 4,\n",
       "       2, 3, 4, 4, 2, 1, 2, 3, 4, 2, 1, 2, 5, 1, 3, 4, 2, 1, 5, 1, 6, 5, 3,\n",
       "       4, 3, 2, 1, 6, 5, 5, 1, 6, 1, 2, 3, 5, 2, 3, 2, 6, 5, 1, 1, 3, 4, 6,\n",
       "       3, 4, 2, 6, 2, 5, 6, 4, 5, 1, 4, 3, 1, 1, 3, 6, 1, 4, 5, 1, 4, 2, 4,\n",
       "       5, 4, 3, 5, 6, 2, 3, 6, 4, 5, 2, 3, 6, 6, 2, 4, 2, 6, 1, 3, 2, 6, 4,\n",
       "       6, 4, 2, 4, 5, 5, 5, 1, 2, 6, 6, 1, 4, 1, 4, 4, 3, 6, 5, 4, 3, 6, 5,\n",
       "       4, 4, 1, 1, 6, 5, 4, 6, 6, 2, 1, 5, 4, 6, 4, 2, 5, 6, 4, 1, 2, 5, 2,\n",
       "       1, 5, 2, 3, 1, 1, 1, 3, 3, 4, 6])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fair_die_roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    176\n",
       "5    174\n",
       "4    171\n",
       "1    167\n",
       "6    163\n",
       "3    149\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sanity check this\n",
    "pd.Series(fair_die_roll).value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Simulate the loaded die using np.random.choice to create a custom discrete distribution\n",
    "\n",
    "loaded_die_roll = np.random.choice(a = range(1,7), p = [.5, .1, .1 ,.1,.1,.1], size=num_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 2, 6, 1, 6, 5, 1, 6, 1, 5, 1, 5, 5, 5, 4, 1, 1, 1, 1, 3, 1, 6,\n",
       "       3, 5, 1, 5, 6, 1, 3, 4, 1, 2, 1, 1, 1, 1, 1, 1, 6, 2, 6, 1, 1, 2, 1,\n",
       "       1, 3, 1, 3, 3, 1, 1, 4, 1, 1, 6, 1, 3, 6, 1, 1, 1, 1, 1, 3, 1, 2, 6,\n",
       "       5, 3, 1, 3, 2, 1, 1, 5, 1, 1, 1, 1, 5, 4, 4, 1, 1, 1, 1, 1, 4, 1, 2,\n",
       "       1, 1, 1, 6, 5, 6, 1, 1, 2, 1, 5, 1, 1, 1, 1, 4, 1, 1, 1, 1, 4, 5, 6,\n",
       "       4, 1, 3, 1, 1, 5, 1, 6, 1, 3, 3, 5, 3, 3, 1, 2, 1, 4, 2, 3, 1, 1, 4,\n",
       "       1, 1, 1, 6, 4, 1, 1, 1, 4, 3, 1, 1, 1, 3, 4, 1, 1, 1, 6, 1, 4, 3, 1,\n",
       "       1, 1, 3, 4, 3, 2, 1, 6, 4, 1, 6, 3, 2, 4, 5, 3, 1, 1, 6, 1, 1, 1, 1,\n",
       "       3, 6, 1, 1, 1, 5, 3, 1, 5, 5, 5, 6, 1, 4, 1, 5, 4, 4, 3, 1, 2, 6, 6,\n",
       "       1, 1, 1, 4, 5, 1, 2, 5, 4, 2, 2, 2, 1, 2, 3, 5, 3, 4, 1, 1, 1, 1, 4,\n",
       "       6, 1, 1, 5, 1, 2, 4, 3, 1, 1, 4, 2, 1, 4, 1, 4, 1, 6, 1, 1, 1, 1, 5,\n",
       "       6, 1, 1, 4, 5, 2, 1, 1, 3, 1, 3, 1, 4, 1, 2, 1, 3, 1, 2, 2, 2, 3, 3,\n",
       "       5, 1, 5, 1, 1, 1, 1, 4, 4, 4, 2, 1, 1, 1, 1, 1, 1, 2, 4, 6, 6, 3, 1,\n",
       "       3, 4, 1, 1, 5, 1, 2, 2, 1, 1, 1, 1, 1, 5, 1, 2, 1, 6, 1, 1, 5, 5, 1,\n",
       "       5, 1, 1, 1, 1, 4, 1, 1, 4, 4, 1, 3, 1, 4, 3, 6, 1, 1, 1, 1, 1, 6, 1,\n",
       "       1, 4, 1, 4, 1, 1, 1, 1, 6, 1, 2, 1, 1, 5, 1, 3, 6, 2, 6, 1, 1, 1, 4,\n",
       "       6, 1, 3, 1, 2, 1, 6, 3, 1, 1, 1, 1, 1, 5, 2, 2, 1, 5, 4, 1, 4, 2, 1,\n",
       "       1, 1, 1, 6, 5, 3, 1, 1, 3, 2, 1, 2, 5, 1, 1, 4, 1, 1, 1, 1, 4, 2, 1,\n",
       "       5, 5, 5, 1, 1, 6, 4, 1, 1, 1, 6, 2, 1, 1, 3, 5, 1, 4, 6, 1, 2, 1, 4,\n",
       "       2, 3, 4, 1, 6, 2, 1, 3, 4, 1, 5, 6, 1, 6, 1, 1, 1, 5, 3, 1, 1, 3, 1,\n",
       "       5, 5, 2, 6, 1, 6, 3, 3, 1, 5, 1, 1, 1, 2, 2, 4, 5, 1, 4, 1, 5, 5, 2,\n",
       "       4, 1, 1, 5, 1, 1, 1, 5, 1, 1, 4, 5, 1, 1, 1, 1, 1, 4, 3, 3, 1, 5, 1,\n",
       "       6, 3, 1, 3, 1, 3, 1, 1, 5, 1, 5, 1, 3, 3, 2, 1, 1, 1, 1, 3, 6, 5, 4,\n",
       "       4, 3, 1, 6, 3, 2, 1, 1, 1, 5, 2, 1, 6, 1, 1, 1, 4, 6, 1, 5, 1, 6, 4,\n",
       "       5, 1, 6, 4, 1, 5, 1, 5, 1, 4, 2, 1, 1, 1, 1, 1, 2, 1, 1, 4, 1, 6, 5,\n",
       "       3, 2, 5, 1, 1, 1, 4, 1, 2, 6, 5, 2, 1, 5, 2, 1, 1, 6, 3, 5, 5, 2, 2,\n",
       "       1, 1, 1, 4, 3, 5, 1, 3, 3, 2, 4, 1, 2, 1, 1, 1, 3, 6, 3, 4, 2, 3, 1,\n",
       "       1, 1, 1, 1, 1, 1, 6, 1, 1, 1, 3, 1, 1, 2, 1, 1, 1, 1, 1, 1, 5, 2, 2,\n",
       "       1, 6, 1, 1, 3, 1, 1, 2, 5, 1, 4, 6, 1, 1, 1, 1, 1, 6, 4, 3, 1, 5, 6,\n",
       "       5, 1, 3, 1, 1, 1, 3, 3, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 6, 3, 3, 1, 2,\n",
       "       1, 3, 6, 3, 5, 4, 1, 6, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 4, 3, 5,\n",
       "       3, 1, 3, 1, 1, 4, 1, 4, 5, 5, 6, 1, 1, 2, 1, 3, 4, 3, 1, 1, 1, 1, 5,\n",
       "       1, 1, 1, 3, 3, 1, 1, 1, 1, 3, 3, 1, 1, 6, 1, 3, 1, 1, 1, 2, 6, 1, 1,\n",
       "       1, 1, 1, 1, 4, 1, 1, 6, 1, 6, 1, 5, 3, 5, 6, 1, 6, 1, 1, 1, 2, 1, 2,\n",
       "       2, 4, 5, 1, 1, 1, 1, 1, 1, 1, 6, 2, 1, 2, 1, 1, 3, 1, 1, 6, 5, 3, 2,\n",
       "       3, 1, 1, 1, 1, 2, 1, 6, 6, 4, 2, 5, 1, 4, 1, 4, 1, 5, 6, 1, 1, 6, 1,\n",
       "       5, 2, 1, 1, 1, 4, 1, 2, 1, 2, 5, 6, 1, 5, 4, 2, 6, 1, 1, 5, 1, 5, 5,\n",
       "       1, 5, 1, 2, 3, 6, 1, 1, 3, 4, 3, 1, 1, 1, 5, 1, 1, 6, 1, 6, 3, 5, 1,\n",
       "       1, 4, 5, 4, 1, 4, 4, 3, 4, 5, 3, 1, 1, 1, 1, 1, 1, 1, 1, 5, 6, 1, 6,\n",
       "       2, 1, 1, 2, 4, 4, 1, 1, 1, 1, 1, 1, 5, 6, 1, 6, 1, 1, 1, 3, 6, 3, 1,\n",
       "       3, 1, 5, 2, 1, 2, 3, 1, 3, 1, 4, 5, 5, 2, 2, 1, 4, 1, 1, 1, 1, 3, 1,\n",
       "       4, 1, 1, 2, 1, 1, 4, 1, 5, 1, 1, 4, 1, 1, 1, 1, 5, 1, 4, 5, 1, 6, 1,\n",
       "       6, 1, 3, 1, 1, 3, 4, 1, 1, 4, 3, 6, 4, 6, 4, 1, 1, 4, 3, 1, 1, 6, 2,\n",
       "       1, 1, 1, 1, 1, 1, 4, 1, 5, 5, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_die_roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    498\n",
       "3    109\n",
       "5    106\n",
       "4    103\n",
       "6     92\n",
       "2     92\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sanity check this\n",
    "pd.Series(loaded_die_roll).value_counts()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Simulate the observed die.  If the coin is heads the observed die is the fair die, if it is tails it\n",
    "#is the loaded die.  There is a quick and sneaky way to accomplish this.\n",
    "\n",
    "observed_die_roll = coin_toss * fair_die_roll + (1-coin_toss) * loaded_die_roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1120000000000001"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean((observed_die_roll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Sanity check this\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lets look at the means - are they what we would expect?\n",
    "\n",
    "print(np.mean(coin_toss))\n",
    "print(np.mean(fair_die_roll))\n",
    "print(np.mean(loaded_die_roll))\n",
    "print(np.mean(observed_die_roll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70068027210884354"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(coin_toss[observed_die_roll==4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.613\n",
      "3.498\n",
      "2.503\n",
      "3.112\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributions and Empirical Distributions\n",
    "\n",
    "Empirical distributions refer to approximations of the \"true\" distribution obtained by sampling data and (essentially) making histograms.  For example, if we look at 1000 realizations of a coin toss we may see 510 heads and 490 tails.  The empirical distribution would be 51% heads, but the true underlying probability may be .5.  The idea is that as we get more and more data, the empirical distribution converges to the true distribution (this is the essence of the *Law of Large Numbers*).\n",
    "\n",
    "In the above, we are using a true distribution to generate data, and examining the empirical distributions.  Typically, Data Science proceeds in the opposite direction -- we have data which we treat as coming from some theoretical distribution, and use it to try and learn about the \"theoretical\" underlying distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Independence of Random Variables\n",
    "\n",
    "What does it mean for two random variables to be independent?\n",
    "\n",
    "We have 4 variables: `coin_toss`, `fair_die_roll`, `loaded_die_roll`, `observed_die_roll`\n",
    "\n",
    "For each pair of variables (how many pairs do we have?) think about whether the two variables in the pair are independent or not.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Type some code here to examine whether certain variables / events are independent or not\n",
    "### e.g. plot distributions or calculate (empirical) probabilities\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question:\n",
    "\n",
    "Suppose `observed_die` = 1, what is the probability that `coin_toss` = 1?  Let's try to solve this analytically and also get an approximate (empirical) answer from our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147\n",
      "103\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7142857142857143"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "print(np.sum(observed_die_roll==4))\n",
    "print(np.sum((observed_die_roll==4) & (coin_toss == 1)))\n",
    "10/14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion of Probability Algebra and Bayes' Rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we create a noisy version of the coin toss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noisy_coin_toss = coin_toss + np.random.randn(num_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEACAYAAACj0I2EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11686b358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Let's plot a histogram to look\n",
    "plt.hist(noisy_coin_toss, bins = 100, range = (-10,10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us \"bin\" the noisy coin toss into 3 cases: x<0, 0<=x<=1, and x>1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "binned_nct = (noisy_coin_toss>1).astype(int) + (noisy_coin_toss>0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    367\n",
       "1    336\n",
       "0    297\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#unique, counts = np.unique(binned_nct, return_counts=True)\n",
    "#print(np.asarray((unique, counts)).T)\n",
    "\n",
    "pd.Series(binned_nct).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the distribution of `observed_die` given that `binned_nct` = 1?  Do you think `observed_die` is independent of the event `binned_nct` == 1?  Is `observed_die` independent of the random variable `binned_nct`?  What is the difference between the previous two statements?\n",
    "\n",
    "\n",
    "How can we characterize \"degrees\" of independence?  Does it make sense to say that variables are \"almost\" independent or \"very\" dependent?  Does it matter if the variables are numerical or categorical?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
