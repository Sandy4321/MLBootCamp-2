{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_csv('36361-0001-Data.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Select markers for Age of first use of variety of drugs, flag for having tried the drug.\n",
    "cols = ['IRCIGAGE',\n",
    " 'IRCDUAGE',\n",
    " 'IRCGRAGE',\n",
    " 'IRSLTAGE',\n",
    " 'IISLTAGE',\n",
    " 'IRCHWAGE',\n",
    " 'IRSNFAGE',\n",
    " 'IRALCAGE',\n",
    " 'IRMJAGE',\n",
    " 'IRCOCAGE',\n",
    " 'IRCRKAGE',\n",
    " 'IRHERAGE',\n",
    " 'IRHALAGE',\n",
    " 'IRLSDAGE',\n",
    " 'IRPCPAGE',\n",
    " 'IRECSAGE',\n",
    " 'IRINHAGE',\n",
    " 'IRANLAGE',\n",
    " 'IROXYAGE',\n",
    " 'IRTRNAGE',\n",
    " 'IRSTMAGE',\n",
    " 'IRMTHAGE',\n",
    " 'IRSEDAGE',\n",
    " 'AGE2',\n",
    " 'IRSEX',\n",
    " 'CIGFLAG',\n",
    " 'SMKFLAG',\n",
    " 'TOBFLAG',\n",
    " 'ALCFLAG',\n",
    " 'MRJFLAG',\n",
    " 'COCFLAG',\n",
    " 'CRKFLAG',\n",
    " 'HERFLAG',\n",
    " 'HALFLAG',\n",
    " 'LSDFLAG',\n",
    " 'PCPFLAG',\n",
    " 'ECSFLAG',\n",
    " 'INHFLAG',\n",
    " 'ANLFLAG',\n",
    " 'OXYFLAG',\n",
    " 'TRQFLAG',\n",
    " 'STMFLAG',\n",
    " 'CPNSTMFG',\n",
    " 'MTHFLAG',\n",
    " 'CPNMTHFG',\n",
    " 'SEDFLAG',\n",
    " 'PSYFLAG2',\n",
    " 'CPNPSYFG',\n",
    " 'SUMFLAG',\n",
    " 'MJOFLAG',\n",
    " 'IEMFLAG',\n",
    " 'CDUFLAG',\n",
    " 'HEALTH',\n",
    " 'COMBATPY',\n",
    " 'SERVICE', \n",
    " 'NOMARR2',\n",
    " 'LANGVER',\n",
    " 'POVERTY2',\n",
    " 'INCOME',\n",
    " 'GOVTPROG',\n",
    " 'IMOTHER',\n",
    " 'EDFAM18',\n",
    " 'IFATHER', \n",
    " 'DRKSUM',\n",
    " 'CABNGAGE',\n",
    " 'DEPRSLIF',\n",
    " 'ANXDLIF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This is the regression data\n",
    "X = df[cols]\n",
    "y = df['DEPNDILL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['YSTART'] = (X[\"IRALCAGE\"] < 15) & (X[\"IRMJAGE\"] < 15)\n",
    "X['YANY'] = (X['IRALCAGE']<15) or (X[\"IRMJAGE\"] < 15) or (X['IRCIGAGE'] < 15) or (X['IRCDUAGE'] <15) or (X['IRCGRAGE']<15) or (X['IRSLTAGE']<15) or (X['IISLTAGE'] <15) or (X['IRCHWAGE']<15) or (X['IRSNFAGE']<15) or (X['IRCOCAGE']<15) or (X['IRCRKAGE']<15) or (X['IRHERAGE']<15) or (X['IRHALAGE']<15) or (X['IRLSDAGE']<15) or (X['IRPCPAGE']<15) or (X['IRECSAGE']<15) or (X['IRINHAGE']<15) or (X['IRANLAGE']<15) || (X['IROXYAGE']<15) or (X['IRTRNAGE']<15) or (X['IRSTMAGE']<15) or (X['IRMTHAGE']<15) or (X['IRSEDAGE']<15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What does the data look like?\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#functions for plotting roc_curves\n",
    "def plot_multi_roc(model, model_r, model_sm, name):\n",
    "    #score all data\n",
    "    y_score = model.predict_proba(X_test)[:,1]\n",
    "    fpr, tpr,_ = roc_curve(y_test, y_score)\n",
    "    #score undersampled data\n",
    "    y_r_score=model_r.predict_proba(X_test)[:,1]\n",
    "    fpr_r, tpr_r,_ = roc_curve(y_test, y_r_score)\n",
    "    #score oversampled data\n",
    "    y_sm_score = model_sm.predict_proba(X_test)[:,1]\n",
    "    fpr_sm, tpr_sm,_ = roc_curve(y_test, y_sm_score)\n",
    "\n",
    "    #roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure()\n",
    "    # Plotting our Baseline..\n",
    "    plt.title(\"MODEL: \"+name)\n",
    "    plt.plot([0,1],[0,1])\n",
    "    plt.plot(fpr,tpr, label = \"all data\")\n",
    "    plt.plot(fpr_r, tpr_r, label = \"resampled\")\n",
    "    plt.plot(fpr_sm, tpr_sm, label = \"smote\")\n",
    "    plt.xlabel('FPR')\n",
    "    plt.ylabel('TPR')\n",
    "    plt.legend(loc='best')\n",
    "\n",
    "def plot_roc(model, name):\n",
    "    #score all data\n",
    "    y_score = model.predict_proba(X_test2)[:,1]\n",
    "    fpr, tpr,_ = roc_curve(y_test2, y_score)\n",
    "\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure()\n",
    "    # Plotting our Baseline..\n",
    "    plt.title(\"MODEL: \"+name)\n",
    "    plt.plot([0,1],[0,1])\n",
    "    plt.plot(fpr,tpr, label = \"all data\")\n",
    "    plt.xlabel('FPR')\n",
    "    plt.ylabel('TPR')\n",
    "    plt.legend(loc='best')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.30, random_state=4321)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform regression on the selected dataset as-is.\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.30, random_state=4321)\n",
    "lr = LogisticRegression()\n",
    "gnb = GaussianNB()\n",
    "#svc = SVC()\n",
    "dtc = DecisionTreeClassifier()\n",
    "rfc = RandomForestClassifier()\n",
    "knn = KNeighborsClassifier()\n",
    "dtc.fit(X_train, y_train)\n",
    "rfc.fit(X_train, y_train)\n",
    "lr.fit(X_train, y_train)\n",
    "gnb.fit(X_train, y_train)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross val for all of the models:\n",
    "model_list = [lr, gnb, dtc, rfc, knn]\n",
    "model_names = ['Logistic Regressor', 'Gaussian Naive Bayes', 'Decision Tree', 'Random Forest', 'KNN']\n",
    "for m, n in zip(model_list, model_names):\n",
    "    print(n)\n",
    "    print(cross_val_score(m, X_train, y_train, scoring='recall'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_param_range = [0.001,0.01,0.1,1,10,100]\n",
    "scores = []\n",
    "for c in C_param_range:\n",
    "    lr = LogisticRegression(C = c)\n",
    "    print(c)\n",
    "    print(cross_val_score(lr, X_train, y_train, scoring='recall'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Build a classification task using 3 informative features\n",
    "\n",
    "\n",
    "rfc_grid = RandomForestClassifier(n_jobs=-1,max_features= 'sqrt' ,n_estimators=50, oob_score = True) \n",
    "\n",
    "param_grid = { \n",
    "    'n_estimators': [100, 300],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "CV_rfc = GridSearchCV(estimator=rfc_grid, param_grid=param_grid, cv= 5)\n",
    "CV_rfc.fit(X_train, y_train)\n",
    "print(CV_rfc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(CV_rfc, X_train, y_train, scoring='recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#oversample the underrepresented data and try the model again\n",
    "\n",
    "sm = SMOTE(random_state=12, ratio = 1.0)\n",
    "X_sm_train, y_sm_train = sm.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sm_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lr_sm = LogisticRegression()\n",
    "gnb_sm = GaussianNB()\n",
    "#svc = SVC()\n",
    "dtc_sm = DecisionTreeClassifier()\n",
    "rfc_sm = RandomForestClassifier(max_features= 'sqrt', n_estimators= 100)\n",
    "knn_sm = KNeighborsClassifier()\n",
    "dtc_sm.fit(X_sm_train, y_sm_train)\n",
    "rfc_sm.fit(X_sm_train, y_sm_train)\n",
    "lr_sm.fit(X_sm_train, y_sm_train)\n",
    "gnb_sm.fit(X_sm_train, y_sm_train)\n",
    "knn_sm.fit(X_sm_train, y_sm_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross val for all of the models:\n",
    "model_list = [lr_sm, gnb_sm, dtc_sm, rfc_sm, knn_sm]\n",
    "model_names = ['Logistic Regressor', 'Gaussian Naive Bayes', 'Decision Tree', 'Random Forest', 'KNN']\n",
    "for m, n in zip(model_list, model_names):\n",
    "    print(n)\n",
    "    print(cross_val_score(m, X_sm_train, y_sm_train, scoring='recall'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now let's try undersampling the oversampled portion:\n",
    "rus = RandomUnderSampler(return_indices=True)\n",
    "X_rus, y_rus, idx_resampled = rus.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_rus = LogisticRegression()\n",
    "gnb_rus = GaussianNB()\n",
    "#svc = SVC()\n",
    "dtc_rus = DecisionTreeClassifier()\n",
    "rfc_rus = RandomForestClassifier(max_features= 'sqrt', n_estimators= 100)\n",
    "knn_rus = KNeighborsClassifier()\n",
    "dtc_rus.fit(X_rus, y_rus)\n",
    "rfc_rus.fit(X_rus, y_rus)\n",
    "lr_rus.fit(X_rus, y_rus)\n",
    "gnb_rus.fit(X_rus, y_rus)\n",
    "knn_rus.fit(X_rus, y_rus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross val for all of the models:\n",
    "model_list = [lr_rus, gnb_rus, dtc_rus, rfc_rus, knn_rus]\n",
    "model_names = ['Logistic Regressor', 'Gaussian Naive Bayes', 'Decision Tree', 'Random Forest', 'KNN']\n",
    "for m, n in zip(model_list, model_names):\n",
    "    print(n)\n",
    "    print(cross_val_score(m, X_rus, y_rus, scoring='recall'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SMOTE data seems to have the best recall. I will use that for modeling.  \n",
    "#Test the logistic regressor params again but with smote data this time\n",
    "\n",
    "C_param_range = [0.001,0.01,0.1,1,10,100]\n",
    "scores = []\n",
    "for c in C_param_range:\n",
    "    lr = LogisticRegression(C = c)\n",
    "    print(c)\n",
    "    print(cross_val_score(lr, X_sm_train, y_sm_train, scoring='recall'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Test KNN with parameters\n",
    "\n",
    "# creating odd list of K for KNN\n",
    "myList = list(range(1,50))\n",
    "\n",
    "# subsetting just the odd ones\n",
    "neighbors = filter(lambda x: x % 2 != 0, myList)\n",
    "\n",
    "# empty list that will hold cv scores\n",
    "cv_scores = []\n",
    "\n",
    "for k in neighbors:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, X_sm_train, y_sm_train, cv=10, scoring='%precision')\n",
    "    cv_scores.append(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores.index(max(cv_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "cross_val_score(knn, X_sm_train, y_sm_train, cv=10, scoring='recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# .99 feels too good to be true.  I think I will stick with Logistic but also look at random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best models are Logistic Regressor and Random Forest.  Plotting the two roc curves against test data.\n",
    "lr_sm\n",
    "rfc_sm\n",
    "\n",
    "\n",
    "#score all data\n",
    "y_score_lr = lr_sm.predict_proba(X_test)[:,1]\n",
    "fpr, tpr,_ = roc_curve(y_test, y_score_lr)\n",
    "y_score_rfc = rfc_sm.predict_proba(X_test)[:,1]\n",
    "fpr_rf, tpr_rf,_ = roc_curve(y_test, y_score_rfc)\n",
    "\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "# Plotting our Baseline..\n",
    "plt.title(\"ROC curve\")\n",
    "plt.plot([0,1],[0,1])\n",
    "plt.plot(fpr,tpr, label = \"Logistic Regressor\")\n",
    "plt.plot(fpr_rf,tpr_rf, label = \"Random Forest\")\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#They are very similar.  I will work with Logistic.\n",
    "y_pred = rfc_sm.predict(X_test)\n",
    "#y_pred_r = rfc_sm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outcome = []\n",
    "for y, z in zip(y_pred, y_test):\n",
    "    if y == 1 & z == 1:\n",
    "        outcome.append('tpos')\n",
    "    elif y== 1 & z == 0:\n",
    "        outcome.append('fpos')\n",
    "    elif y == 0 & z == 0:\n",
    "        outcome.append('tneg')\n",
    "    elif y == 0 & z == 1:\n",
    "        outcome.append('fneg')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome.count('fneg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(C = 10, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outcome = []\n",
    "for y, z in zip(y_pred, y_test):\n",
    "    if y == 1 & z == 1:\n",
    "        outcome.append('tpos')\n",
    "    elif y== 1 & z == 0:\n",
    "        outcome.append('fpos')\n",
    "    elif y == 0 & z == 0:\n",
    "        outcome.append('tneg')\n",
    "    elif y == 0 & z == 1:\n",
    "        outcome.append('fneg')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_k = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del X_test['predicted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_sm.fit(X_sm_train, y_sm_train)\n",
    "y_pred_sm = lr_sm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_data = X_test\n",
    "predicted_data['predicted'] = outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "false_pos = predicted_data[predicted_data['predicted'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_pos[false_pos['AGE2'] < 12].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(list(zip(rfc.feature_importances_, X.columns)), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "param_test1 = {'n_estimators':list(range(50,200,25))}\n",
    "gsearch1 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, min_samples_split=500,min_samples_leaf=50,max_depth=8,max_features='sqrt',subsample=0.8,random_state=10), \n",
    "param_grid = param_test1, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch1.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbc = gsearch1.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cross_val_score(gbc, X_train, y_train, scoring='recall'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cross_val_score(gbc, X_train, y_train, scoring='precision'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cross_val_score(gbc, X_train, y_train, scoring='accuracy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cross_val_score(gbc, X_sm_train, y_sm_train, scoring='recall'))\n",
    "print(cross_val_score(gbc, X_sm_train, y_sm_train, scoring='precision'))\n",
    "print(cross_val_score(gbc, X_sm_train, y_sm_train, scoring='accuracy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cross_val_score(gbc, X_rus, y_rus, scoring='recall'))\n",
    "print(cross_val_score(gbc, X_rus, y_rus, scoring='precision'))\n",
    "print(cross_val_score(gbc, X_rus, y_rus, scoring='accuracy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbc.fit(X_sm_train, y_sm_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(list(zip(gbc.feature_importances_, X.columns)), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cross_val_score(rfc, X_train, y_train, scoring='recall'))\n",
    "print(cross_val_score(rfc, X_train, y_train, scoring='precision'))\n",
    "print(cross_val_score(rfc, X_train, y_train, scoring='accuracy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cross_val_score(rfc, X_sm_train, y_sm_train, scoring='recall'))\n",
    "print(cross_val_score(rfc, X_sm_train, y_sm_train, scoring='precision'))\n",
    "print(cross_val_score(rfc, X_sm_train, y_sm_train, scoring='accuracy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cross_val_score(rfc, X_rus, y_rus, scoring='recall'))\n",
    "print(cross_val_score(rfc, X_rus, y_rus, scoring='precision'))\n",
    "print(cross_val_score(rfc, X_rus, y_rus, scoring='accuracy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfc.fit(X_rus, y_rus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cross_val_score(lr, X_train, y_train, scoring='recall'))\n",
    "print(cross_val_score(lr, X_train, y_train, scoring='precision'))\n",
    "print(cross_val_score(lr, X_train, y_train, scoring='accuracy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cross_val_score(lr, X_sm_train, y_sm_train, scoring='recall'))\n",
    "print(cross_val_score(lr, X_sm_train, y_sm_train, scoring='precision'))\n",
    "print(cross_val_score(lr, X_sm_train, y_sm_train, scoring='accuracy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cross_val_score(lr, X_rus, y_rus, scoring='recall'))\n",
    "print(cross_val_score(lr, X_rus, y_rus, scoring='precision'))\n",
    "print(cross_val_score(lr, X_rus, y_rus, scoring='accuracy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm2 = SMOTE(random_state=12, ratio = 0.3)\n",
    "X_sm2_train, y_sm2_train = sm2.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cross_val_score(lr, X_train, y_train, scoring='recall'))\n",
    "print(cross_val_score(lr, X_train, y_train, scoring='precision'))\n",
    "print(cross_val_score(lr, X_train, y_train, scoring='accuracy'))\n",
    "print(cross_val_score(lr, X_train, y_train, scoring='f1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(lr, X_train, y_train, scoring='recall').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(lr, X_train, y_train, scoring='precision').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(X_train, y_train)\n",
    "pig = lr.predict(X_test)\n",
    "len(pig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(lr, X_train, y_train, scoring='recall').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_confusion_matrix(confusion_matrix, class_names, figsize = (10,7), fontsize=14):\n",
    "    \"\"\"Prints a confusion matrix, as returned by sklearn.metrics.confusion_matrix, as a heatmap.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    confusion_matrix: numpy.ndarray\n",
    "        The numpy.ndarray object returned from a call to sklearn.metrics.confusion_matrix. \n",
    "        Similarly constructed ndarrays can also be used.\n",
    "    class_names: list\n",
    "        An ordered list of class names, in the order they index the given confusion matrix.\n",
    "    figsize: tuple\n",
    "        A 2-long tuple, the first value determining the horizontal size of the ouputted figure,\n",
    "        the second determining the vertical size. Defaults to (10,7).\n",
    "    fontsize: int\n",
    "        Font size for axes labels. Defaults to 14.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    matplotlib.figure.Figure\n",
    "        The resulting confusion matrix figure\n",
    "    \"\"\"\n",
    "    df_cm = pd.DataFrame(\n",
    "        confusion_matrix, index=class_names, columns=class_names, \n",
    "    )\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    try:\n",
    "        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cfm = confusion_matrix(y_test, pig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = cfm.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(list(zip(pd.Series(lr.coef_[0]), X.columns)), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_vals = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(y_pred_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_addicts = X_test[y_pred_vals > y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_addicts.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_addicts[predicted_addicts.AGE2 < 10].AGE2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_addicts[predicted_addicts.AGE2 >= 10].AGE2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_adict_proba = lr.predict_proba(predicted_addicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_adict_proba.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decision threshold\n",
    "type(predicted_adict_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_adict_proba[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_addicts['probability'] = predicted_adict_proba[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bins = [.50, .60, .70, .80, .90, 1.00]\n",
    "labels = [50, 60, 70, 80, 90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_addicts['prob_group'] = pd.cut(predicted_addicts['probability'], bins, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_addicts['prob_group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_addicts['prob_group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_addicts[predicted_addicts.AGE2 < 8].prob_group.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_addicts[(predicted_addicts.AGE2 >= 8) & (predicted_addicts.AGE2 <14)].prob_group.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_addicts[(predicted_addicts.AGE2 > 13)].prob_group.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score = lr.predict_proba(X_test)[:,1]\n",
    "fpr, tpr,_ = roc_curve(y_test, y_score)\n",
    "\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.grid(linestyle='-', linewidth='0.5', color='white')\n",
    "ax.set_facecolor('white')\n",
    "# Plotting our Baseline..\n",
    "plt.title(\"Logistic Regression ROC\")\n",
    "plt.plot([0,1],[0,1])\n",
    "plt.plot(fpr,tpr, label = \"all data\")\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
