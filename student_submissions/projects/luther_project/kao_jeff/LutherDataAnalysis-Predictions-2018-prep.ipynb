{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions with our best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/anaconda/lib/python3.5/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# To plot matplotlib figures inline on the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Lasso, LassoCV, Ridge, RidgeCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score, train_test_split, KFold\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from luther_common import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# categories to predict\n",
    "pred_categories = ['pts_per_g',\n",
    "         'fg_per_g','fga_per_g',\n",
    "         'fg3_per_g','fg3a_per_g',\n",
    "         'ft_per_g','fta_per_g',\n",
    "         'trb_per_g','blk_per_g',\n",
    "         'stl_per_g','ast_per_g',\n",
    "         'tov_per_g'\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load our predictive and standardization models\n",
    "from sklearn.externals import joblib\n",
    "estimators = dict()\n",
    "standardizers = dict()\n",
    "predictions = dict()\n",
    "\n",
    "for category in pred_categories:\n",
    "    estimators[category]=joblib.load('best_linreg_predictor_'+category+'.pkl')\n",
    "    standardizers[category]=joblib.load('best_linreg_standardizer_'+category+'.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load our data:\n",
    "X_df = pd.read_csv('LEBRON_data_feng.csv', index_col=0)\n",
    "y_df = pd.read_csv('LEBRON_target.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/j2kao/Documents/METIS/metis_projects/luther/luther_common.py:157: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  ready_X.drop(excluded_columns, axis=1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# best prediction using 'D' mask:\n",
    "level = 'D'\n",
    "for category in pred_categories:\n",
    "    #piggyback off the existing mask function to mask the X and y\n",
    "    ready_X, ready_y = mask_data(category, level, X_df, y_df)\n",
    "    std_ready_X = standardizers[category].transform(ready_X)\n",
    "    predictions[category] = estimators[category].predict(std_ready_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pts_per_g\n",
      "2.16106937219\n",
      "fg_per_g\n",
      "0.816117450206\n",
      "fga_per_g\n",
      "1.67254534001\n",
      "fg3_per_g\n",
      "0.215503174381\n",
      "fg3a_per_g\n",
      "0.52232031868\n",
      "ft_per_g\n",
      "0.519309684101\n",
      "fta_per_g\n",
      "0.641199021875\n",
      "trb_per_g\n",
      "0.869022845894\n",
      "blk_per_g\n",
      "0.15165832259\n",
      "stl_per_g\n",
      "0.188236839746\n",
      "ast_per_g\n",
      "0.555098977011\n",
      "tov_per_g\n",
      "0.310396935841\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "for category in pred_categories:\n",
    "    print(category)\n",
    "    print(mean_absolute_error(predictions[category], y_df[category]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#first set up players back to 2015\n",
    "player_seasons_df = pd.read_csv('player_seasons_list_processed.csv')\n",
    "player_seasons_df = player_seasons_df[player_seasons_df['season_year'] >= 2015]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.9 s, sys: 119 ms, total: 15 s\n",
      "Wall time: 15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 5. replace the season rows with weighted averages where relevant\n",
    "# Define lambda functions to:\n",
    "# compute the weighted average (by g)\n",
    "# keep the value of non-averaged rows\n",
    "mean_wt_by_g = lambda x: np.average(x, weights=player_seasons_df.loc[x.index, 'g'])\n",
    "keep = lambda x: x.iloc[0]\n",
    "# Define a dictionary with the functions to apply for each column:\n",
    "f = {\n",
    "'age':keep,\n",
    "'ast_per_g':mean_wt_by_g,\n",
    "'blk_per_g':mean_wt_by_g,\n",
    "'canonical':keep,\n",
    "'drb_per_g':mean_wt_by_g,\n",
    "'eff_raw':sum,\n",
    "'eff_ratio':sum,\n",
    "'fg2_per_g':mean_wt_by_g,\n",
    "'fg2a_per_g':mean_wt_by_g,\n",
    "'fg3_per_g':mean_wt_by_g,\n",
    "'fg3a_per_g':mean_wt_by_g,\n",
    "'fg_per_g':mean_wt_by_g,\n",
    "'fga_per_g':mean_wt_by_g,\n",
    "'ft_per_g':mean_wt_by_g,\n",
    "'fta_per_g':mean_wt_by_g,\n",
    "'g':np.sum,\n",
    "'mp_per_g':mean_wt_by_g,\n",
    "'name':keep,\n",
    "'orb_per_g':mean_wt_by_g,\n",
    "'pf_per_g':mean_wt_by_g,\n",
    "'pts_per_g':mean_wt_by_g,\n",
    "'season':keep,\n",
    "'stl_per_g':mean_wt_by_g,\n",
    "'team_id':keep,\n",
    "'tov_per_g':mean_wt_by_g,\n",
    "'trb_per_g':mean_wt_by_g,\n",
    "'season_year':keep,\n",
    "'pos_C':mean_wt_by_g,\n",
    "'pos_PF':mean_wt_by_g,\n",
    "'pos_PG':mean_wt_by_g,\n",
    "'pos_SF':mean_wt_by_g,\n",
    "'pos_SG':mean_wt_by_g,\n",
    "'poscat':mean_wt_by_g,\n",
    "'team_pace':mean_wt_by_g\n",
    "}\n",
    "# Groupby and aggregate with the dictionary:\n",
    "final_player_seasons_df = player_seasons_df.groupby(['season_year', 'canonical']).agg(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_player_seasons_df_2018 = final_player_seasons_df[final_player_seasons_df['season_year'] == 2017]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 486 entries, (2017.0, abrinal01) to (2017.0, zubaciv01)\n",
      "Data columns (total 34 columns):\n",
      "trb_per_g      486 non-null float64\n",
      "pos_PF         486 non-null float64\n",
      "drb_per_g      486 non-null float64\n",
      "eff_ratio      486 non-null float64\n",
      "canonical      486 non-null object\n",
      "name           486 non-null object\n",
      "fg2_per_g      486 non-null float64\n",
      "pts_per_g      486 non-null float64\n",
      "ast_per_g      486 non-null float64\n",
      "stl_per_g      486 non-null float64\n",
      "tov_per_g      486 non-null float64\n",
      "fg2a_per_g     486 non-null float64\n",
      "pos_SF         486 non-null float64\n",
      "blk_per_g      486 non-null float64\n",
      "ft_per_g       486 non-null float64\n",
      "fga_per_g      486 non-null float64\n",
      "season         486 non-null object\n",
      "g              486 non-null int64\n",
      "pos_PG         486 non-null float64\n",
      "season_year    486 non-null float64\n",
      "eff_raw        486 non-null float64\n",
      "fta_per_g      486 non-null float64\n",
      "pf_per_g       486 non-null float64\n",
      "poscat         486 non-null float64\n",
      "fg3_per_g      486 non-null float64\n",
      "fg_per_g       486 non-null float64\n",
      "fg3a_per_g     486 non-null float64\n",
      "mp_per_g       486 non-null float64\n",
      "pos_SG         486 non-null float64\n",
      "orb_per_g      486 non-null float64\n",
      "team_id        486 non-null object\n",
      "pos_C          486 non-null float64\n",
      "age            486 non-null float64\n",
      "team_pace      486 non-null float64\n",
      "dtypes: float64(29), int64(1), object(4)\n",
      "memory usage: 135.9+ KB\n"
     ]
    }
   ],
   "source": [
    "final_player_seasons_df_2018.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "# we are trying to create 2018 players\n",
    "final_player_seasons_df_2018['age'] = final_player_seasons_df_2018['age'].apply(lambda x: x + 1)\n",
    "final_player_seasons_df_2018['season_year'] = final_player_seasons_df_2018['season_year'].apply(lambda x: x + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_player_seasons_df = final_player_seasons_df.append(final_player_seasons_df_2018, ignore_index=True)\n",
    "df = final_player_seasons_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in the player individual stats\n",
    "players_df = pd.read_csv('player_list.csv', index_col=0)\n",
    "# calculate player's individual stats \n",
    "# height and weight for the player (seems like those are the useful values)\n",
    "# rookie year\n",
    "players_df['height'] = players_df['height'].fillna('6-6')\n",
    "players_df['weight'] = players_df['weight'].fillna(230)\n",
    "def height_str_to_height_inches(height_str):\n",
    "    ft_str, in_str = (height_str.split('-'))\n",
    "    return float(ft_str) * 12 + float(in_str)\n",
    "players_df['height_inches'] = players_df['height'].apply(height_str_to_height_inches)\n",
    "players_df['rookie_yr'] = players_df['year_min']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.9 s, sys: 304 ms, total: 26.2 s\n",
      "Wall time: 27.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# process: iterate through each row in the dataset, \n",
    "# if the previous num_yrs_back years stats exist:\n",
    "# append prev num_yrs_back year stats to X (break multiple rows into cols)\n",
    "# append ppg to y\n",
    "num_yrs_back = 3\n",
    "X_df = pd.DataFrame()\n",
    "y_df = pd.DataFrame()\n",
    "# for each row, count it as a row if we can get something from the year before that row\n",
    "for _ , row in df.iterrows():\n",
    "    temp_df = df[(df['season_year'] >= row['season_year']-num_yrs_back) &\n",
    "                 (df['season_year'] <= row['season_year']) &\n",
    "                 (df['canonical'] == row['canonical'])]\n",
    "    if temp_df.shape[0] == num_yrs_back + 1:\n",
    "        year_row_wide = pd.DataFrame()\n",
    "        years_ago = num_yrs_back\n",
    "        for _ , year_row in temp_df.iterrows():\n",
    "            #need to go across the rows and append with 'years_ago'\n",
    "            for col_name , year_row_item in year_row.iteritems():\n",
    "                year_row_wide[col_name + '_{}_ya'.format(years_ago)] = [year_row_item]\n",
    "            years_ago -= 1 #not used yet, put into column name\n",
    "        X_df = X_df.append(year_row_wide)\n",
    "        y_df = y_df.append(row)\n",
    "X_df.reset_index(inplace=True, drop=True)\n",
    "y_df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AFTER player_seasons_df is separated, merge player's individual stats into X_df \n",
    "temp_players_df = players_df.loc[:,['canonical','height_inches','weight','rookie_yr']]\n",
    "X_df = pd.merge(X_df, temp_players_df, how='left', left_on='canonical_0_ya', right_on='canonical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate number of years in league and drop rookie year\n",
    "for years_ago in range(0,4):\n",
    "    suffix = '_{}_ya'.format(years_ago)\n",
    "    X_df['yrs_in_league'+suffix] = X_df['season_year'+suffix] - X_df['rookie_yr']\n",
    "X_df.drop('rookie_yr', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# our columns got messed up in all that copying and pasting...\n",
    "X_df = X_df.reindex_axis(sorted(X_df.columns), axis=1)\n",
    "y_df = y_df.reindex_axis(sorted(y_df.columns), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load our predictive and standardization models\n",
    "from sklearn.externals import joblib\n",
    "estimators = dict()\n",
    "standardizers = dict()\n",
    "\n",
    "for category in pred_categories:\n",
    "    estimators[category]=joblib.load('naive_linreg_predictor_'+category+'.pkl')\n",
    "    standardizers[category]=joblib.load('naive_linreg_standardizer_'+category+'.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/j2kao/Documents/METIS/metis_projects/luther/luther_common.py:157: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  ready_X.drop(excluded_columns, axis=1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# basic prediction using 'B' mask:\n",
    "level = 'B'\n",
    "for category in pred_categories:\n",
    "    #piggyback off the existing mask function to mask the X and y\n",
    "    ready_X, ready_y = mask_data(category, level, X_df, y_df)\n",
    "    std_ready_X = standardizers[category].transform(ready_X)\n",
    "    y_predict = estimators[category].predict(std_ready_X)\n",
    "    X_df[category+'_pred'] = y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a raw efficiency score for the X _pred's and for player_seasons_df:\n",
    "#    (PTS + REB + AST + STL + BLK − ((FGA − FGM) + (FTA − FTM) + TO)) multiply by g to weight it\n",
    "X_df['eff_raw_pred'] = (X_df['pts_per_g_pred'] +\\\n",
    "                    X_df['trb_per_g_pred'] +\\\n",
    "                    X_df['ast_per_g_pred'] +\\\n",
    "                    X_df['stl_per_g_pred'] +\\\n",
    "                    X_df['blk_per_g_pred'] -\\\n",
    "                   ((X_df['fga_per_g_pred'] - X_df['fg_per_g_pred']) +\\\n",
    "                    (X_df['fta_per_g_pred'] - X_df['ft_per_g_pred']) +\\\n",
    "                     X_df['tov_per_g_pred'])) * 72#X_df['g_pred'] (assume playing 72 games...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Note: we lost a bit of nuance in the data due to row combination, ignore it for the time being\n",
    "# read in the performance of the player for each season (no predictions, broken down by season)\n",
    "player_seasons_df = pd.read_csv('player_seasons_list_processed.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.31 s, sys: 136 ms, total: 5.45 s\n",
      "Wall time: 5.49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#pre-process; re-label a couple of columns to use\n",
    "player_seasons_df['season_year_prev'] = player_seasons_df['season_year'].apply(lambda x: x-1)\n",
    "\n",
    "# now we 1) try to predict a NEW eff_ratio and 2) copy last year's pace over as a prediction of pace (at the end)\n",
    "for index, player_season in X_df.iterrows():\n",
    "\n",
    "    #get a df of all the people who played in the position on the same team that year and sum their contribution scores\n",
    "    teammates_df = player_seasons_df[(player_seasons_df['season_year'] == player_season['season_year_0_ya']) &\n",
    "                                   (player_seasons_df['team_id'] == player_season['team_id_0_ya']) &\n",
    "                                   (player_seasons_df['poscat'] == player_season['poscat_0_ya'])\n",
    "                                  ]\n",
    "\n",
    "    # merge in raw predictions from X_df\n",
    "    pred_teammates_df = pd.merge(teammates_df, \n",
    "                                 X_df.loc[:,['canonical','season_year_0_ya','eff_raw_pred']], \n",
    "                                 how='left', \n",
    "                                 left_on=['canonical','season_year'], \n",
    "                                 right_on=['canonical','season_year_0_ya'])\n",
    "    # merge in numbers from last year\n",
    "    pred_teammates_df = pd.merge(pred_teammates_df,\n",
    "                                 player_seasons_df.loc[:,['canonical','season_year_prev','eff_raw']],\n",
    "                                 how='left', \n",
    "                                 left_on=['canonical','season_year'], \n",
    "                                 right_on=['canonical','season_year_prev'])\n",
    "    \n",
    "    #eff_raw_pred (predicted), #eff_raw_x (this year -- should actually not be used), #eff_raw_y (last year)\n",
    "    # if we didn't have the eff_raw_pred, replace it\n",
    "    for teammate_index, teammate_season in pred_teammates_df.iterrows():\n",
    "        if pd.isnull(teammate_season['eff_raw_pred']):\n",
    "            if not pd.isnull(teammate_season['eff_raw_y']):\n",
    "                pred_teammates_df.loc[teammate_index, 'eff_raw_pred'] = teammate_season['eff_raw_y']\n",
    "            else:\n",
    "                #this player didn't HAVE a previous season..\n",
    "                pred_teammates_df.loc[teammate_index, 'eff_raw_pred'] = 0\n",
    "    \n",
    "    #finally, take contribution score and divide contribution score of position of the team\n",
    "    num = player_season['eff_raw_pred']\n",
    "    denom = sum(pred_teammates_df['eff_raw_pred'])\n",
    "    #careful of division by zero or zero divided by zero...\n",
    "    \n",
    "    if denom == 0:\n",
    "        X_df.loc[index, 'eff_ratio_pred'] = 1\n",
    "    else:\n",
    "        X_df.loc[index, 'eff_ratio_pred'] = num/denom\n",
    "    \n",
    "#     #some debug code\n",
    "#     if X_df.loc[index, :].isnull().any():\n",
    "#         print(\"NULL:\")\n",
    "#         print(index)\n",
    "#         print(\"SEASON:\")\n",
    "#         print(player_season)\n",
    "#         print(\"TEAMMATES:\")\n",
    "#         print(pred_teammates_df)\n",
    "#         print(\"NUM:\")\n",
    "#         print(num)\n",
    "#         print(\"DENOM:\")\n",
    "#         print(denom)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy over pace from 1 year ago\n",
    "X_df['team_pace_pred'] = X_df['team_pace_1_ya']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_0_ya</th>\n",
       "      <th>age_1_ya</th>\n",
       "      <th>age_2_ya</th>\n",
       "      <th>age_3_ya</th>\n",
       "      <th>ast_per_g_0_ya</th>\n",
       "      <th>ast_per_g_1_ya</th>\n",
       "      <th>ast_per_g_2_ya</th>\n",
       "      <th>ast_per_g_3_ya</th>\n",
       "      <th>blk_per_g_0_ya</th>\n",
       "      <th>blk_per_g_1_ya</th>\n",
       "      <th>...</th>\n",
       "      <th>ft_per_g_pred</th>\n",
       "      <th>fta_per_g_pred</th>\n",
       "      <th>trb_per_g_pred</th>\n",
       "      <th>blk_per_g_pred</th>\n",
       "      <th>stl_per_g_pred</th>\n",
       "      <th>ast_per_g_pred</th>\n",
       "      <th>tov_per_g_pred</th>\n",
       "      <th>eff_raw_pred</th>\n",
       "      <th>eff_ratio_pred</th>\n",
       "      <th>team_pace_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>324.000000</td>\n",
       "      <td>324.000000</td>\n",
       "      <td>324.000000</td>\n",
       "      <td>324.000000</td>\n",
       "      <td>324.000000</td>\n",
       "      <td>324.000000</td>\n",
       "      <td>324.000000</td>\n",
       "      <td>324.000000</td>\n",
       "      <td>324.000000</td>\n",
       "      <td>324.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>324.000000</td>\n",
       "      <td>324.000000</td>\n",
       "      <td>324.000000</td>\n",
       "      <td>324.000000</td>\n",
       "      <td>324.000000</td>\n",
       "      <td>324.000000</td>\n",
       "      <td>324.000000</td>\n",
       "      <td>324.000000</td>\n",
       "      <td>324.0</td>\n",
       "      <td>324.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>29.033951</td>\n",
       "      <td>28.033951</td>\n",
       "      <td>27.033951</td>\n",
       "      <td>26.033951</td>\n",
       "      <td>2.159162</td>\n",
       "      <td>2.159162</td>\n",
       "      <td>2.181653</td>\n",
       "      <td>2.170637</td>\n",
       "      <td>0.426862</td>\n",
       "      <td>0.426862</td>\n",
       "      <td>...</td>\n",
       "      <td>1.535321</td>\n",
       "      <td>1.992695</td>\n",
       "      <td>3.759968</td>\n",
       "      <td>0.396220</td>\n",
       "      <td>0.678319</td>\n",
       "      <td>2.061691</td>\n",
       "      <td>1.185218</td>\n",
       "      <td>742.195457</td>\n",
       "      <td>1.0</td>\n",
       "      <td>96.438797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.940984</td>\n",
       "      <td>3.940984</td>\n",
       "      <td>3.940984</td>\n",
       "      <td>3.940984</td>\n",
       "      <td>1.934280</td>\n",
       "      <td>1.934280</td>\n",
       "      <td>1.903858</td>\n",
       "      <td>1.883980</td>\n",
       "      <td>0.407856</td>\n",
       "      <td>0.407856</td>\n",
       "      <td>...</td>\n",
       "      <td>1.414762</td>\n",
       "      <td>1.749492</td>\n",
       "      <td>2.303447</td>\n",
       "      <td>0.376954</td>\n",
       "      <td>0.375183</td>\n",
       "      <td>1.745379</td>\n",
       "      <td>0.731624</td>\n",
       "      <td>419.333645</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.294608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.327445</td>\n",
       "      <td>-0.433349</td>\n",
       "      <td>0.270108</td>\n",
       "      <td>-0.061133</td>\n",
       "      <td>-0.048188</td>\n",
       "      <td>-0.074249</td>\n",
       "      <td>-0.033106</td>\n",
       "      <td>5.941716</td>\n",
       "      <td>1.0</td>\n",
       "      <td>91.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.626513</td>\n",
       "      <td>0.839986</td>\n",
       "      <td>2.144569</td>\n",
       "      <td>0.138815</td>\n",
       "      <td>0.411633</td>\n",
       "      <td>0.862549</td>\n",
       "      <td>0.714636</td>\n",
       "      <td>458.774386</td>\n",
       "      <td>1.0</td>\n",
       "      <td>94.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.649375</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.093019</td>\n",
       "      <td>1.442374</td>\n",
       "      <td>3.222356</td>\n",
       "      <td>0.298028</td>\n",
       "      <td>0.619481</td>\n",
       "      <td>1.524894</td>\n",
       "      <td>1.015964</td>\n",
       "      <td>629.070424</td>\n",
       "      <td>1.0</td>\n",
       "      <td>96.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>32.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.973662</td>\n",
       "      <td>2.644727</td>\n",
       "      <td>4.801484</td>\n",
       "      <td>0.509754</td>\n",
       "      <td>0.895698</td>\n",
       "      <td>2.683114</td>\n",
       "      <td>1.510795</td>\n",
       "      <td>988.527043</td>\n",
       "      <td>1.0</td>\n",
       "      <td>98.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>41.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>11.200000</td>\n",
       "      <td>11.200000</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>8.532633</td>\n",
       "      <td>10.189564</td>\n",
       "      <td>13.334094</td>\n",
       "      <td>2.291496</td>\n",
       "      <td>1.827869</td>\n",
       "      <td>9.868914</td>\n",
       "      <td>4.872941</td>\n",
       "      <td>2322.652008</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101.300000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 141 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         age_0_ya    age_1_ya    age_2_ya    age_3_ya  ast_per_g_0_ya  \\\n",
       "count  324.000000  324.000000  324.000000  324.000000      324.000000   \n",
       "mean    29.033951   28.033951   27.033951   26.033951        2.159162   \n",
       "std      3.940984    3.940984    3.940984    3.940984        1.934280   \n",
       "min     22.000000   21.000000   20.000000   19.000000        0.000000   \n",
       "25%     26.000000   25.000000   24.000000   23.000000        0.900000   \n",
       "50%     29.000000   28.000000   27.000000   26.000000        1.500000   \n",
       "75%     32.000000   31.000000   30.000000   29.000000        2.800000   \n",
       "max     41.000000   40.000000   39.000000   38.000000       11.200000   \n",
       "\n",
       "       ast_per_g_1_ya  ast_per_g_2_ya  ast_per_g_3_ya  blk_per_g_0_ya  \\\n",
       "count      324.000000      324.000000      324.000000      324.000000   \n",
       "mean         2.159162        2.181653        2.170637        0.426862   \n",
       "std          1.934280        1.903858        1.883980        0.407856   \n",
       "min          0.000000        0.000000        0.000000        0.000000   \n",
       "25%          0.900000        0.900000        0.900000        0.100000   \n",
       "50%          1.500000        1.649375        1.600000        0.300000   \n",
       "75%          2.800000        2.800000        3.000000        0.500000   \n",
       "max         11.200000       11.700000       10.200000        2.600000   \n",
       "\n",
       "       blk_per_g_1_ya       ...        ft_per_g_pred  fta_per_g_pred  \\\n",
       "count      324.000000       ...           324.000000      324.000000   \n",
       "mean         0.426862       ...             1.535321        1.992695   \n",
       "std          0.407856       ...             1.414762        1.749492   \n",
       "min          0.000000       ...            -0.327445       -0.433349   \n",
       "25%          0.100000       ...             0.626513        0.839986   \n",
       "50%          0.300000       ...             1.093019        1.442374   \n",
       "75%          0.500000       ...             1.973662        2.644727   \n",
       "max          2.600000       ...             8.532633       10.189564   \n",
       "\n",
       "       trb_per_g_pred  blk_per_g_pred  stl_per_g_pred  ast_per_g_pred  \\\n",
       "count      324.000000      324.000000      324.000000      324.000000   \n",
       "mean         3.759968        0.396220        0.678319        2.061691   \n",
       "std          2.303447        0.376954        0.375183        1.745379   \n",
       "min          0.270108       -0.061133       -0.048188       -0.074249   \n",
       "25%          2.144569        0.138815        0.411633        0.862549   \n",
       "50%          3.222356        0.298028        0.619481        1.524894   \n",
       "75%          4.801484        0.509754        0.895698        2.683114   \n",
       "max         13.334094        2.291496        1.827869        9.868914   \n",
       "\n",
       "       tov_per_g_pred  eff_raw_pred  eff_ratio_pred  team_pace_pred  \n",
       "count      324.000000    324.000000           324.0      324.000000  \n",
       "mean         1.185218    742.195457             1.0       96.438797  \n",
       "std          0.731624    419.333645             0.0        2.294608  \n",
       "min         -0.033106      5.941716             1.0       91.600000  \n",
       "25%          0.714636    458.774386             1.0       94.900000  \n",
       "50%          1.015964    629.070424             1.0       96.200000  \n",
       "75%          1.510795    988.527043             1.0       98.000000  \n",
       "max          4.872941   2322.652008             1.0      101.300000  \n",
       "\n",
       "[8 rows x 141 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_df.to_csv('LEBRON_data_feng_2018.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
