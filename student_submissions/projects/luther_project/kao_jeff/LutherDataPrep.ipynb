{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation functions\n",
    "* Use this to prepare data for use by the models we are applying:\n",
    "* linear & polynomial regression (keep it to the min explanatory variables) => explanation\n",
    "* random forest (throw more stuff in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To plot matplotlib figures inline on the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Lasso, LassoCV, Ridge, RidgeCV\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from luther_common import season_str_to_season_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in team's seasons\n",
    "team_seasons_df = pd.read_csv('team_seasons_list.csv', index_col=0)\n",
    "# add season_year column\n",
    "team_seasons_df['season_year'] = team_seasons_df['season'].apply(season_str_to_season_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in the player individual stats\n",
    "players_df = pd.read_csv('player_list.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in the performance of the player for each season\n",
    "player_seasons_df = pd.read_csv('player_seasons_list.csv', index_col=0)\n",
    "# add season_year column\n",
    "player_seasons_df['season_year'] = player_seasons_df['season'].apply(season_str_to_season_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate player's individual stats \n",
    "# height and weight for the player (seems like those are the useful values)\n",
    "# rookie year\n",
    "players_df['height'] = players_df['height'].fillna('6-6')\n",
    "players_df['weight'] = players_df['weight'].fillna(230)\n",
    "def height_str_to_height_inches(height_str):\n",
    "    ft_str, in_str = (height_str.split('-'))\n",
    "    return float(ft_str) * 12 + float(in_str)\n",
    "players_df['height_inches'] = players_df['height'].apply(height_str_to_height_inches)\n",
    "players_df['rookie_yr'] = players_df['year_min']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#general cleanup of player_seasons_df\n",
    "#get rid of percentage stats (not useful)\n",
    "player_seasons_df = player_seasons_df.select(lambda x: not re.search('_pct', x), axis=1)\n",
    "#get rid of other not useful columns\n",
    "player_seasons_df.drop('lg_id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FIRST. reduce the data we are working with: only data from analysis_start_year onwards\n",
    "analysis_start_year = 1985 # 1985 is the max data set (bc of team names, etc.)\n",
    "player_seasons_df = player_seasons_df[player_seasons_df['season_year'] >= analysis_start_year]\n",
    "\n",
    "# cleaning player seasons\n",
    "# 1. if there are multiple rows for the same season, drop any row that is 'TOT'\n",
    "player_seasons_df = player_seasons_df[(player_seasons_df['team_id'] != 'TOT')]\n",
    "# 2. dummy variables for pos\n",
    "player_seasons_df = pd.get_dummies(player_seasons_df, columns=['pos'])\n",
    "# 3. hack 'categorical' variable for position (1=PG ... 5=C)\n",
    "player_seasons_df['poscat'] = \\\n",
    "(player_seasons_df['pos_PG'] * 1 + \n",
    "player_seasons_df['pos_SG'] * 2 + \n",
    "player_seasons_df['pos_SF'] * 3 + \n",
    "player_seasons_df['pos_PF'] * 4 + \n",
    "player_seasons_df['pos_C'] * 5 ) / \\\n",
    "(player_seasons_df['pos_PG'] * 1 + \n",
    "player_seasons_df['pos_SG'] * 1 + \n",
    "player_seasons_df['pos_SF'] * 1 + \n",
    "player_seasons_df['pos_PF'] * 1 + \n",
    "player_seasons_df['pos_C'] * 1 )\n",
    "\n",
    "# 4. get an efficiency score for the player:\n",
    "#    (PTS + REB + AST + STL + BLK − ((FGA − FGM) + (FTA − FTM) + TO)) multiply by g to weight it\n",
    "player_seasons_df['eff_raw'] = (player_seasons_df['pts_per_g'] +\\\n",
    "                            player_seasons_df['trb_per_g'] +\\\n",
    "                            player_seasons_df['ast_per_g'] +\\\n",
    "                            player_seasons_df['stl_per_g'] +\\\n",
    "                            player_seasons_df['blk_per_g'] -\\\n",
    "                           ((player_seasons_df['fga_per_g'] - player_seasons_df['fg_per_g']) +\\\n",
    "                            (player_seasons_df['fta_per_g'] - player_seasons_df['ft_per_g']) +\\\n",
    "                             player_seasons_df['tov_per_g'])) * player_seasons_df['g']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# merge player's team's season into player_seasons_df BEFORE player_seasons_df is separated\n",
    "temp_team_seasons_df = team_seasons_df.loc[:,['season_year',\n",
    "                                            'initials',\n",
    "                                            'pace']]\n",
    "temp_team_seasons_df.rename(columns={'initials':'team_id',\n",
    "                                     'pace':'team_pace'}, inplace=True)\n",
    "player_seasons_df = pd.merge(player_seasons_df, \n",
    "                             temp_team_seasons_df, \n",
    "                             how='left', \n",
    "                             left_on=['season_year','team_id'], \n",
    "                             right_on=['season_year','team_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 2s, sys: 451 ms, total: 1min 2s\n",
      "Wall time: 1min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# merge player's season into the roster - relative strengths of players in the same position\n",
    "for index, player_season in player_seasons_df.iterrows():\n",
    "    #get a df of all the people who played in the position on the same team that year and sum their contribution scores\n",
    "    teammates_df = player_seasons_df[(player_seasons_df['season_year'] == player_season['season_year']) &\n",
    "                                   (player_seasons_df['team_id'] == player_season['team_id']) &\n",
    "                                   (player_seasons_df['poscat'] == player_season['poscat'])\n",
    "                                  ]\n",
    "    #take contribution score and divide contribution score of position of the team\n",
    "    denom = sum(teammates_df['eff_raw'])\n",
    "    num = player_season['eff_raw']\n",
    "    player_seasons_df.loc[index, 'eff_ratio'] = num/denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the interim player_seasons (it's useful..)\n",
    "player_seasons_df.to_csv('player_seasons_list_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 5. replace the season rows with weighted averages where relevant\n",
    "# Define lambda functions to:\n",
    "# compute the weighted average (by g)\n",
    "# keep the value of non-averaged rows\n",
    "mean_wt_by_g = lambda x: np.average(x, weights=player_seasons_df.loc[x.index, 'g'])\n",
    "keep = lambda x: x.iloc[0]\n",
    "# Define a dictionary with the functions to apply for each column:\n",
    "f = {\n",
    "'age':keep,\n",
    "'ast_per_g':mean_wt_by_g,\n",
    "'blk_per_g':mean_wt_by_g,\n",
    "'canonical':keep,\n",
    "'drb_per_g':mean_wt_by_g,\n",
    "'eff_raw':sum,\n",
    "'eff_ratio':sum,\n",
    "'fg2_per_g':mean_wt_by_g,\n",
    "'fg2a_per_g':mean_wt_by_g,\n",
    "'fg3_per_g':mean_wt_by_g,\n",
    "'fg3a_per_g':mean_wt_by_g,\n",
    "'fg_per_g':mean_wt_by_g,\n",
    "'fga_per_g':mean_wt_by_g,\n",
    "'ft_per_g':mean_wt_by_g,\n",
    "'fta_per_g':mean_wt_by_g,\n",
    "'g':np.sum,\n",
    "'mp_per_g':mean_wt_by_g,\n",
    "'name':keep,\n",
    "'orb_per_g':mean_wt_by_g,\n",
    "'pf_per_g':mean_wt_by_g,\n",
    "'pts_per_g':mean_wt_by_g,\n",
    "'season':keep,\n",
    "'stl_per_g':mean_wt_by_g,\n",
    "'team_id':keep,\n",
    "'tov_per_g':mean_wt_by_g,\n",
    "'trb_per_g':mean_wt_by_g,\n",
    "'season_year':keep,\n",
    "'pos_C':mean_wt_by_g,\n",
    "'pos_PF':mean_wt_by_g,\n",
    "'pos_PG':mean_wt_by_g,\n",
    "'pos_SF':mean_wt_by_g,\n",
    "'pos_SG':mean_wt_by_g,\n",
    "'poscat':mean_wt_by_g,\n",
    "'team_pace':mean_wt_by_g\n",
    "}\n",
    "# Groupby and aggregate with the dictionary:\n",
    "final_player_seasons_df = player_seasons_df.groupby(['season_year', 'canonical']).agg(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = final_player_seasons_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# process: iterate through each row in the dataset, \n",
    "# if the previous num_yrs_back years stats exist:\n",
    "# append prev num_yrs_back year stats to X (break multiple rows into cols)\n",
    "# append ppg to y\n",
    "num_yrs_back = 3\n",
    "X_df = pd.DataFrame()\n",
    "y_df = pd.DataFrame()\n",
    "# for each row, count it as a row if we can get something from the year before that row\n",
    "for _ , row in df.iterrows():\n",
    "    temp_df = df[(df['season_year'] >= row['season_year']-num_yrs_back) &\n",
    "                 (df['season_year'] <= row['season_year']) &\n",
    "                 (df['canonical'] == row['canonical'])]\n",
    "    if temp_df.shape[0] == num_yrs_back + 1:\n",
    "        year_row_wide = pd.DataFrame()\n",
    "        years_ago = num_yrs_back\n",
    "        for _ , year_row in temp_df.iterrows():\n",
    "            #need to go across the rows and append with 'years_ago'\n",
    "            for col_name , year_row_item in year_row.iteritems():\n",
    "                year_row_wide[col_name + '_{}_ya'.format(years_ago)] = [year_row_item]\n",
    "            years_ago -= 1 #not used yet, put into column name\n",
    "        X_df = X_df.append(year_row_wide)\n",
    "        y_df = y_df.append(row)\n",
    "X_df.reset_index(inplace=True, drop=True)\n",
    "y_df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# AFTER player_seasons_df is separated, merge player's individual stats into X_df \n",
    "temp_players_df = players_df.loc[:,['canonical','height_inches','weight','rookie_yr']]\n",
    "X_df = pd.merge(X_df, temp_players_df, how='left', left_on='canonical_0_ya', right_on='canonical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate number of years in league and drop rookie year\n",
    "for years_ago in range(0,4):\n",
    "    suffix = '_{}_ya'.format(years_ago)\n",
    "    X_df['yrs_in_league'+suffix] = X_df['season_year'+suffix] - X_df['rookie_yr']\n",
    "X_df.drop('rookie_yr', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check that there are no nulls\n",
    "X_df[X_df.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_df.shape\n",
    "#check nulls\n",
    "#X_df[X_df.isnull().any(axis=1)]\n",
    "#fill nans?\n",
    "#X_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_df.tail(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# our columns got messed up in all that copying and pasting...\n",
    "X_df = X_df.reindex_axis(sorted(X_df.columns), axis=1)\n",
    "y_df = y_df.reindex_axis(sorted(y_df.columns), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####### WE HAVE OUR DATA AND TARGET SO WRITE IT TO FILE #######\n",
    "X_df.to_csv('LEBRON_data.csv')\n",
    "y_df.to_csv('LEBRON_target.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
